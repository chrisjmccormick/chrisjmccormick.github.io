---

layout: post

title:  "Steps and Seeds in Stable Diffusion"

date:   2023-01-11 8:00:00 -0800

comments: true

image: https://drive.google.com/uc?export=view&id=1SKyqrglsqcdIiybAhGSt5YwDRkhOKhFn

tags: Stable Diffusion, AI Art, Tutorial, Step Count, Seed

---


In this series of posts I‚Äôll be explaining the most common settings in stable diffusion generation tools, using DreamStudio and Automatic1111 as the examples.

This first post will cover the **steps** slider and the **seed** value, and then further posts will cover the ‚Äúcfg scale‚Äù, and ‚Äúsampler‚Äù.


## Steps

Let‚Äôs start with the step count.

In DreamStudio, this is labeled ‚ÄúSteps‚Äù, with the description ‚ÄúHow many steps to spend generating (diffusing) your image.‚Äù


![Inference steps setting in DreamStudio](https://drive.google.com/uc?export=view&id=1t8SeAzjRYDERnXspzNoZ5JoV8idCWr8T)

In Automatic1111, it‚Äôs labeled ‚ÄúSampling steps‚Äù:


![Step slider in Auto1111](https://drive.google.com/uc?export=view&id=17xsDvkcIHjDDtEqcPYAmfESkAbP_hta6)


With the following tooltip: ‚ÄúHow many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results‚Äù. That‚Äôs a pretty good summary, but let me give you a little more insight into how it works.

[Update 4/7/23]: A new version of DreamStudio has been released with a re-designed interface! The screenshots in this post come from the original version, which is still accessible [here](https://legacy.dreamstudio.ai/dream). The settings I'm explaining are still there in the new version, just laid out differently.   

### What Happens in a ‚ÄúStep‚Äù

Stable Diffusion generates images by starting with **random noise**, and then, using your text prompt as guidance, gradually ‚Äú**de-noises**‚Äù the image. (It treats the initial random noise as though it were actually a very noisy image, and it‚Äôs trying to **recover** the _supposed_ original image, using your text description to inform it).

In the illustration below, the image on the far left is our **initial noise**, and the image on the far right is the finished result. I ran this generation with 25 steps; the center illustration shows the state of the image at each step, and you can see how the image is gradually getting cleaned up.

![From noise to artwork](https://drive.google.com/uc?export=view&id=1vWAL0IUFNWrT3Q5IbULIOmr4svZL9-GW)

No matter how many steps you use, the process _always starts and ends the same way_‚Äìyou start with random noise, and end up with a completely de-noised image.

What the ‚Äústeps‚Äù setting _actually_ controls is how many steps we **divide** this process into. So a **higher count** divides the process into more steps, and each step will make a **smaller change** to the image. 

If you use what would be considered a relatively **low** number of steps, you‚Äôll find that the images tend to be less detailed and contain more **flaws**. 

In the below examples, the result at 5 steps is a complete mess, and 10 and 15 both have uneven irises. 

![Step count 5 to 20](https://drive.google.com/uc?export=view&id=12c205yfoh272Qgv-rWyCz29ZSCUx1Gwt)

![Step count 20 to 50](https://drive.google.com/uc?export=view&id=1SKyqrglsqcdIiybAhGSt5YwDRkhOKhFn)


There does appear to be some correlation between the number of steps and the amount of detail, but I‚Äôd argue that beyond a certain point you‚Äôre really just getting different variations.

It also seems that you _can_ go **too high**. In this example, it looks like 100 and 150 steps starts to reintroduce some problems.

![Overdoing the steps](https://drive.google.com/uc?export=view&id=1wqAFN1v9Gib66Sxii0kAUb19ZlYu_pPx)

Side Note: The effect of the number of steps can also depend significantly on the choice of ‚Äúsampler‚Äù--something we'll look at more closely in a few posts. The illustrations above were generated with "Euler A", which is the default selection in Auto1111.

### Common Misconceptions

There are a couple misconceptions I‚Äôve seen around the effect of the step count that I think come from over-simplified explanations. 

The **first misconception** is that increasing the step count means ‚Äú**continue refining** the image longer‚Äù. 

You might run for 10 steps, look at the result and think, ‚ÄúI like that, but I‚Äôd like to see it more cleaned up, so I‚Äôm going to try running it for 5 more steps by setting the step count to 15.‚Äù 

In reality, if you look at my earlier example and compare 10 steps vs 20 steps, it‚Äôs pretty clear that 20 steps is not just a ‚Äúmore refined‚Äù version of 10 steps. They‚Äôre  different images!

Remember, it‚Äôs always the same process, the step count is just _how many intervals_ you _divide_ the process into. The different subdivisions will cause the model to follow slightly **different paths**. 

The **second misconception** is that higher step counts will always yield higher quality results, and we‚Äôve seen how that‚Äôs not the case (in our comparison of 50, 100, and 150 steps). 


### Steps & ‚ÄúCompute Cost‚Äù

There‚Äôs a more practical impact of the step count as well: It affects **how long** the image generation takes‚Äìmore steps will mean you have to **wait longer** to see your result. 

The Stable Diffusion ‚Äúmodel‚Äù is a _dizzyingly_ large Neural Network. For those familiar with the concept, it contains roughly **1 billion** parameters! The number of mathematical operations required to run a _single step_ is on the order of _trillions_.

Tools like DreamStudio run the model for you on ‚ÄúGPUs‚Äù--the **graphics card** that you normally use for playing video games. 

However, the GPUs they typically use are tailored towards this type of math-heavy, scientific computing (This is Nvidia‚Äôs ‚ÄúTesla‚Äù line of GPUs, such as the Tesla T4 or Tesla A100). These specialized GPUs are outrageously expensive! 

Below is a **Tesla A100**; its original MSRP was **$32k**! ü§Ø

![Tesla A100 product photo](https://m.media-amazon.com/images/I/411mNK+mP-L._AC_SY580_.jpg)

When you use a paid tool like DreamStudio, they are going to **charge** you (using a ‚Äú**credits**‚Äù system) based on the number of steps you run. The compute cost is also directly related to the **size of the image** you want to generate, so higher image resolutions are going to cost more credits.

![Credits in DreamStudio](https://drive.google.com/uc?export=view&id=1lakzPtdKM0mS6JLojG_NlpCZ00WH-Xin)


### Preview Images using Few Steps

Given the longer weight times and higher cost of running more steps, a strategy some people use is to first generate images with a **low** step count, just to get a general sense of each of the images. Then, for any results that look promising, they go back and **re-run** these for a **higher** number of steps to get a quality image.

The way to ‚Äúre-run‚Äù a particular image is using something called the ‚Äúseed‚Äù value, which we‚Äôll look at next.


## Seed Value

The ‚Äúseed‚Äù is a number like `145391` which, if you specify it to Stable Diffusion, will always generate the **exact same image**. (provided you keep everything else the same, too) 

![Manual seed setting in DreamStudio](https://drive.google.com/uc?export=view&id=1vFngK1yT2qHdC55_prXrd7ZGjGh9UbZb)

This allows you to try and tweak an image that you like. You can, for example, make **small changes** to the **prompt**, or change the number of inference steps, and get results that all look like **variations** of your ‚Äúbase‚Äù result. 

(For example, to generate my earlier example images demonstrating the effect of the step count, I used the _same seed and prompt_, but varied the steps).

Note that there‚Äôs _no relationship_ between how close the seed numbers are and how similar the images will be. If you change the seed number by 1, you‚Äôll get a completely different result. For example, the below images have seeds that differ by 1 (‚Ä¶201, ‚Ä¶202, and ‚Ä¶203). 

![Nearby seeds are different](https://drive.google.com/uc?export=view&id=1PvJBEEYfoVMAe-IEENMyVC7UjvgXDUFn)

They have some similarity, of course, because they all used the same prompt.


### Aside: How do Seeds Work?

For those curious‚Ä¶

In computers, **random number generators** aren‚Äôt _truly_ random. For a given starting point (‚Äúseed‚Äù), the generator will always spit out the exact **same sequence** of ‚Äúrandom‚Äù numbers! 

Creating the initial random noise involves setting the different pixels to random values. But as long as the seed is the same, the noise image will be **identical**! 

One more thing‚Ä¶ With Stable Diffusion, if you specify ‚Äú**-1**‚Äù then it will randomly choose a seed / seeds for you‚Ä¶ using another random number generator to select the seed values! üòÇ

So how do we make sure _that_ generator gives us a random seed?? ü§î

When you don‚Äôt provide a seed, my understanding is that the generator will base the seed on something that will always be unique, such as the _current date and time_. 


### Setting the Seed

I‚Äôll conclude by just pointing out where to locate and set the seed value in these tools.

In **DreamStudio**, if you **hover** over the image, you‚Äôll see the seed value here:

![Find the seed value in DreamStudio](https://drive.google.com/uc?export=view&id=1zhIB4ynyNI-kUhrZxDPMbVsvIyWZipFB)

Clicking on the seed value seems to copy it to the clipboard and the seed field for you.

In order to actually _set_ the seed value in DreamStudio, you must **set the number of images to 1**. Otherwise the seed field is hidden from view.

![Manual seed setting in DreamStudio](https://drive.google.com/uc?export=view&id=1vFngK1yT2qHdC55_prXrd7ZGjGh9UbZb)


In Automatic1111, it‚Äôs more straightforward:


![Set the seed value in Automatic1111](https://drive.google.com/uc?export=view&id=1m6At4jC4ZQAr1a0cP7MD27BitmLMK2zF)


You can find the seed used to generate an image in Auto1111 by looking at the output window, or the filename, or by opening the image in the ‚ÄúPNG Info‚Äù tab.

